# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U2o6GgwDs3YS7k_AEjcQD9ZPNUD-4GH6

### 1. Getting the data and uploading it into our google drive.
"""

# # Mounting the google drive(Of Pheonix Squadron)

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
uploaded = files.upload()

!mkdir ~/.kaggle
!mv kaggle.json ~/.kaggle/kaggle.json

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d andrewmvd/retinal-disease-classification

import zipfile
with zipfile.ZipFile('/content/retinal-disease-classification.zip','r') as zip_ref:
  zip_ref.extractall('Diabetic Retinopathy')

import os
os.remove('/content/retinal-disease-classification.zip')

"""### 2. Setting the Paths."""

import os

Data_path = '/content/Diabetic Retinopathy'

Training_set = os.path.join(Data_path,'Training_Set','Training_Set')
Testing_set = os.path.join(Data_path,'Test_Set','Test_Set')
Validation_set = os.path.join(Data_path,'Evaluation_Set','Evaluation_Set')

Training_set

Testing_set

Validation_set

Training_images = os.path.join(Training_set,'Training/')
Testing_images = os.path.join(Testing_set,'Test/')
Validation_images = os.path.join(Validation_set,'Validation/')

Training_images

Testing_images

Validation_images

Training_labels = os.path.join(Training_set,'RFMiD_Training_Labels.csv')
Testing_labels = os.path.join(Testing_set,'RFMiD_Testing_Labels.csv')
Validation_labels = os.path.join(Validation_set,'RFMiD_Validation_Labels.csv')

Training_labels

Testing_labels

Validation_labels

"""### 3. Importing the necessary modules and reading the labels: """

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import cv2
import random
import tensorflow as tf

from tensorflow import keras
from google.colab import files
from sklearn.utils import shuffle
from keras.models import Sequential
from keras.callbacks import ModelCheckpoint
from keras.layers.convolutional import Conv2D
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Dense, Activation, Flatten
from keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, classification_report

Train_df = pd.read_csv(Training_labels)
Test_df = pd.read_csv(Testing_labels)
Val_df = pd.read_csv(Validation_labels)

"""### 4. Basic EDA"""

Train_df.head()

Test_df.head()

Val_df.head()

Train_df.drop(columns=Train_df.columns[3:],axis=1,inplace=True)
Test_df.drop(columns=Test_df.columns[3:],axis=1,inplace=True)
Val_df.drop(columns=Val_df.columns[3:],axis=1,inplace=True)

Train_df.drop(columns=['Disease_Risk'],axis=1,inplace=True)
Test_df.drop(columns=['Disease_Risk'],axis=1,inplace=True)
Val_df.drop(columns=['Disease_Risk'],axis=1,inplace=True)

Train_df.head()

Test_df.head()

Val_df.head()

Train_df.describe()

Val_df.describe()

Train_df.info()

Val_df.info()

Train_df.isna().sum()

Val_df.isna().sum()

"""### 5. Getting the file paths for the images."""

Train_df['filepath'] = Train_df['ID'].apply(lambda x: Training_images + str(x) + '.png')
Val_df['filepath'] = Val_df['ID'].apply(lambda x: Validation_images + str(x) + '.png')
Test_df['filepath'] = Test_df['ID'].apply(lambda x: Testing_images + str(x) + '.png')

Train_df['filepath'][0]

Val_df['filepath'][0]

Test_df['filepath'][0]

"""### 6. Sample Images"""

Train_df['DR'].value_counts()

Val_df['DR'].value_counts()

ax = sns.countplot(x='DR',data=Train_df)
for p in ax.patches:
  ax.annotate(f'{p.get_height()}',(p.get_x()+p.get_width()/2.,p.get_height()),ha='center',va='bottom')

plt.show()

# Getting random eye images from the Train Image paths
random_eye_images = [np.random.choice(Train_df['filepath']) for i in range(8)]

print("Display Random Images")

# Setting the figure size to 20px horizontally and 10px vertically.
plt.figure(figsize=(10, 3))

# Plotting 9 random images of the eyes.
for i in range(8):
  plt.subplot(2, 4, i+1)                # plt.subplot(nrows, ncols, index) nrows: no.of rows, ncols: no.of cols, index: selecting the subplot.
  img = plt.imread(random_eye_images[i])  # Reading the image using plt.imread function.
  plt.imshow(img)                         # Showing the images by plotting them.
  plt.axis('off')                         # Not taking the axis.
  
plt.tight_layout()                        # Used to adjust padding between the subplots.

"""### 7. Generating Train Images for the model"""

# Concatenating Train and Validation Data for more training examples.

train_Data = pd.concat([Train_df, Val_df])

# Out of 2500+ images, 508 images have Diabetic Retinopathy

train_Data['DR'].value_counts()

# Defining a function that returns a dataframe with 40% 'DR' and 60% 'NO DR' labelled images 

def balance_Data(data, feature):
  class_01 = data[data[feature] == 1]
  class_00 = data[data[feature] == 0]
  return shuffle(pd.concat([class_01, class_00.sample(n = round(1.5 * len(class_01)))]))

# Getting our new Train Dataframe

bal_Train_Data = balance_Data(train_Data, 'DR')

# Number of images in our Train Data

bal_Train_Data['DR'].value_counts()

"""### 8. Preprocessing of Images"""

# Load and preprocess the Images

from PIL import Image

def img2Gray(image_Paths):
  gray_Images = []

  for image_Path in image_Paths:
      gray_Image = Image.open(image_Path).resize((224, 224))
      gray_Array = np.array(gray_Image)
      norm_Array = gray_Array / 255.0
      reshaped_Array = norm_Array.reshape(224, 224, 3)
      gray_Images.append(reshaped_Array)
      
  gray_Images = np.array(gray_Images)
  return gray_Images

train_Features = img2Gray(bal_Train_Data['filepath'])

train_Targets = bal_Train_Data['DR']

"""### 9. Creating a models folder in google drive"""

os.chdir('/content/drive/MyDrive/')

!mkdir Models

os.chdir('/content/')

"""### 10. Specifying the Checkpoints for the model."""

!mkdir Sequential

filepath = "/content/drive/MyDrive/Models/Sequential/-{epoch:02d}-{recall:.02f}.h5"                                        # Getting the epoch and recall as filename for saving model as a file

# Specifying checkpoints for the model

checkpoints = ModelCheckpoint(
    filepath,
    monitor = 'recall',
    verbose = 1,
    save_best_only = True,
    mode = 'max'
    )

import tensorflow as tf
# Load the .h5 file
model = tf.keras.models.load_model('sequential.h5')

"""### 10(2). Testing and Evaluation of Sequential Model"""

test_Array = img2Gray(Test_df['filepath'])

# Evaluate the model on the test set

test_loss, test_acc = seq_model.evaluate(test_Array, Test_df['DR'])
print('Test Recall:', test_acc)

test_Predictions = seq_model.predict(test_Array)

# Getting the mean of the Test_Predictions.

np.mean(test_Predictions)

test_Predictions_Bin = []
for prediction in test_Predictions:
  test_Predictions_Bin.append(0) if prediction <= np.mean(test_Predictions) else test_Predictions_Bin.append(1)

pd.DataFrame(test_Predictions_Bin).value_counts()

Test_df['DR'].value_counts()

seq_confusion_mat = confusion_matrix( Test_df['DR'],test_Predictions_Bin)

# Plotting the Confusion Matrix for the model.

sns.heatmap(confusion_matrix(Test_df['DR'],test_Predictions_Bin,), annot = True, cmap = 'inferno', fmt = 'd')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

"""### 12. Testing the model by predicting on an image taken from the User"""

# print("Please uploade your Fundus Image Below: ")
# uploaded = files.upload()

# image_Path = ""
# filelist = os.listdir('/content/')
# for file in filelist:
#     if (file.endswith(".png")):
#         image_Path += file

image_Path_1 = '/content/1.png'
image_Path_2 = '/content/5.png'

plt.figure(figsize = (10, 3))
plt.imshow(cv2.cvtColor(cv2.imread(image_Path_2), cv2.COLOR_BGR2RGB))

path_List_1 = [image_Path_2]

seq_user_pred = seq_model.predict(img2Gray(path_List_1))[0][0]*100

incv3_user_pred = incv3_model.predict(img2Gray(path_List_1))[0][0]*100

print(f"Probability of Having Diabetic Retinopathy(Sequential model) : {seq_user_pred : .2f} %")

print(f"Probability of Having Diabetic Retinopathy(InceptionV3 model) : {incv3_user_pred : .2f} %")

